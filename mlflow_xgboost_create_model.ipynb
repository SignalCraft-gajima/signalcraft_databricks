{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4752731-92b6-4d2e-8ec4-abbb9fd6196c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 필수 라이브러리 설치\n",
    "%pip install xgboost mlflow scikit-learn pandas --upgrade --prefer-binary\n",
    "\n",
    "# 설치 후 커널 자동 재시작 (코드 실행 전 세션 초기화)\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3f4a2f6-de94-4a6a-806c-409fd4d6f0dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 중복 생성 방지 및 재현율 개선 버전(2026-02-24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a43c107-df22-43e8-8c20-51cf0398d39a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- [설정부: 유저 환경에 맞춰 수정] ---\n",
    "CATALOG = \"signalcraft_databricks\"    # 실제 카탈로그명\n",
    "SCHEMA = \"default\"  # 실제 스키마명\n",
    "MODEL_NAME = f\"{CATALOG}.{SCHEMA}.churn_predictor\"\n",
    "\n",
    "# UC 모드 활성화\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# --- [1단계: Spark 데이터 전처리 (안정성 및 성능 최적화)] ---\n",
    "\n",
    "# 1. 테이블 로드 및 이력 데이터 사전 집계\n",
    "snapshot_df = spark.table(f\"{CATALOG}.{SCHEMA}.dlt_gold_user_behavior_snapshot\")\n",
    "history_df = spark.table(f\"{CATALOG}.{SCHEMA}.dlt_silver_daily_watch_time_rt\") \\\n",
    "    .select(\"user_id\", \"event_date\").withColumnRenamed(\"event_date\", \"activity_date\")\n",
    "\n",
    "h_agg = history_df.select(\"user_id\", \"activity_date\").distinct()\n",
    "\n",
    "# 2. 시차 레이블링 Join (수정 포인트: 조인 키를 리스트로 전달)\n",
    "# 이렇게 하면 결과 데이터프레임에 user_id가 딱 하나만 남습니다.\n",
    "training_set_spark = snapshot_df.join(\n",
    "    h_agg,\n",
    "    (snapshot_df[\"user_id\"] == h_agg[\"user_id\"]) & \n",
    "    (h_agg[\"activity_date\"] > snapshot_df[\"event_date\"]) & \n",
    "    (h_agg[\"activity_date\"] <= F.date_add(snapshot_df[\"event_date\"], 7)),\n",
    "    \"left_outer\"\n",
    ").drop(h_agg[\"user_id\"]) # 조인 후 h 테이블의 user_id를 명시적으로 제거\n",
    "\n",
    "# 3. 레이블 생성 및 Safe Zone 필터링\n",
    "max_history_date = history_df.select(F.max(\"activity_date\")).collect()[0][0]\n",
    "\n",
    "# snapshot_cols를 미리 정의 (중복 방지를 위해 select로 명시)\n",
    "snapshot_cols = snapshot_df.columns\n",
    "\n",
    "training_set_spark = training_set_spark.groupBy(snapshot_cols).agg(\n",
    "    F.max(\"activity_date\").alias(\"latest_activity\")\n",
    ").withColumn(\n",
    "    \"label\", \n",
    "    F.when(F.col(\"latest_activity\").isNull(), 1).otherwise(0)\n",
    ").filter(\n",
    "    F.col(\"event_date\") <= F.date_sub(F.lit(max_history_date), 7)\n",
    ").drop(\"latest_activity\")\n",
    "\n",
    "# 4. Pandas 변환 및 시계열 정렬 (Random Split 방지)\n",
    "df = training_set_spark.toPandas()\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df = df.sort_values('event_date').reset_index(drop=True)\n",
    "\n",
    "# --- [2단계: 피처 엔지니어링 및 인코딩] ---\n",
    "\n",
    "# Ordinal Encoding: 위험도 순서 부여\n",
    "risk_map = {'Active': 0, 'Soft Churn': 1, 'Dormant': 2, 'Churned': 3}\n",
    "df['risk_level_encoded'] = df['churn_risk_level'].map(risk_map).fillna(0)\n",
    "\n",
    "# One-Hot Encoding: 범주형 변수 처리\n",
    "df = pd.get_dummies(df, columns=['segment'], prefix='seg')\n",
    "\n",
    "# 핵심 신호: 변화율(Ratio) 피처 생성\n",
    "df['watch_time_ratio'] = df['watch_time_7d_min'] / (df['watch_time_30d_min'] / 4 + 1)\n",
    "df['active_days_ratio'] = df['active_days_7'] / (df['active_days_30'] / 4 + 1)\n",
    "\n",
    "# 학습 피처 리스트 (데이터 누수 위험이 있는 churn_reason은 제외)\n",
    "features = [\n",
    "    'daily_watch_time_min', 'watch_time_7d_min', 'watch_time_30d_min',\n",
    "    'active_days_7', 'active_days_30', 'days_since_last_login',\n",
    "    'watch_time_ratio', 'active_days_ratio', 'risk_level_encoded'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "# 클래스 분포 확인\n",
    "class_counts = y.value_counts()\n",
    "print(f\"전체 클래스 분포:\\n{class_counts}\")\n",
    "\n",
    "if len(class_counts) < 2:\n",
    "    raise ValueError(f\"학습 데이터에 클래스가 하나뿐입니다. (현재 클래스: {class_counts.index.tolist()}) \"\n",
    "                     \"데이터 필터링 조건이나 기간을 확인하세요.\")\n",
    "\n",
    "# 시계열 분리 후 다시 확인\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# 학습셋에 두 클래스가 모두 있는지 최종 확인\n",
    "train_classes = y_train.unique()\n",
    "if len(train_classes) < 2:\n",
    "    print(\"⚠️ 경고: 학습셋에 클래스가 부족합니다. 무작위 분리로 일시 전환합니다.\")\n",
    "    # 시계열 순서보다 클래스 균형이 우선인 경우 (데이터가 적을 때)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# --- [3단계: 모델 학습 및 MLflow 등록] ---\n",
    "\n",
    "# 재현율 강화를 위한 가중치 설정 (기존 비율의 1.8배)\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    scale_pos_weight=pos_weight,\n",
    "    eval_metric='aucpr',           # Precision-Recall 최적화\n",
    "    early_stopping_rounds=50,\n",
    "    tree_method='hist',            # 서버리스 속도 최적화\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"SignalCraft_Churn_Run_v4\") as run:\n",
    "    # 1. 모델 학습\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=10\n",
    "    )\n",
    "\n",
    "    # 2. 예측 및 확률값 계산\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_05 = (y_proba > 0.5).astype(int)       # 기본 임계값 기준\n",
    "    \n",
    "    # 3. 메트릭 계산 및 로깅 (MLflow Dashboard에서 확인 가능)\n",
    "    # 기본 임계값(0.5) 기준 지표\n",
    "    mlflow.log_metric(\"auc_roc\", roc_auc_score(y_test, y_proba))\n",
    "    mlflow.log_metric(\"recall_0.5\", recall_score(y_test, y_pred_05))\n",
    "    mlflow.log_metric(\"precision_0.5\", precision_score(y_test, y_pred_05))\n",
    "\n",
    "    # 4. 모델 및 파라미터 저장\n",
    "    mlflow.log_params(model.get_params()) # 하이퍼파라미터 자동 저장\n",
    "    \n",
    "    # 모델 등록 및 Signature 자동 생성\n",
    "    signature = mlflow.models.infer_signature(X_train, model.predict(X_train))\n",
    "    model_info = mlflow.xgboost.log_model(\n",
    "        model, \n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(3),\n",
    "        registered_model_name=MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Alias 설정\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    client.set_registered_model_alias(MODEL_NAME, \"latest\", model_info.registered_model_version)\n",
    "\n",
    "print(f\"✅ 모델 및 메트릭 저장 완료 (Version: {model_info.registered_model_version})\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "xgboost",
     "hyperopt",
     "mlflow"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mlflow_xgboost_create_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}